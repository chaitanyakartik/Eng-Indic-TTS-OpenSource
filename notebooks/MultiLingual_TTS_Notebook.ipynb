{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##TTS Indic"
      ],
      "metadata": {
        "id": "oVl2C369fStJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 1. Install System Dependencies\n",
        "# !apt-get install -y libsndfile1-dev ffmpeg enchant\n",
        "\n",
        "# # 2. Install PyTorch\n",
        "# !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "\n",
        "# # 3. Clone and Set Up the Trainer\n",
        "# !git clone https://github.com/gokulkarthik/Trainer\n",
        "# %cd Trainer\n",
        "# !pip install -e .[all]\n",
        "# %cd ..\n",
        "# # Apply any necessary edits (upload modified files if required)\n",
        "\n",
        "# # 4. Clone and Set Up the TTS Repository\n",
        "# !git clone https://github.com/gokulkarthik/TTS\n",
        "# %cd TTS\n",
        "# !pip install -e .[all]\n",
        "# %cd ..\n",
        "# # Apply any necessary edits (upload modified files if required)\n",
        "\n",
        "# # 5. Install Additional Requirements\n",
        "# !pip install -r requirements.txt\n",
        "\n",
        "# # 6. Run Scripts\n",
        "# # Use the relevant script like `synthesize.py` to test the setup.\n",
        "# # Example: Replace with your actual script and parameters#\n",
        "# #!python TTS/bin/synthesize.py --help\n"
      ],
      "metadata": {
        "id": "M8WbD5RBlw_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !python3 -m TTS.bin.synthesize \\\n",
        "#     --text \"Hello, world! This is a TTS synthesis example.\" \\\n",
        "#     --model_path \"/content/Fastpitch/best_model.pth\" \\\n",
        "#     --config_path \"/content/Fastpitch/config.json\" \\\n",
        "#     --vocoder_path \"/content/Hifigan/best_model.pth\" \\\n",
        "#     --vocoder_config_path \"/content/Hifigan/config.json\" \\\n",
        "#     --out_path \"output/audio.wav\"\n"
      ],
      "metadata": {
        "id": "D8Sda0yRs92X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/smtiitm/Fastspeech2_HS?tab=readme-ov-file"
      ],
      "metadata": {
        "id": "Vy9yoGKnlPsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TTS FAST SPEECH"
      ],
      "metadata": {
        "id": "ESJNCcokfM1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Git LFS (Large File Storage)\n",
        "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.python.sh | bash\n",
        "!sudo apt-get install git-lfs\n",
        "!git lfs install\n",
        "\n",
        "# Clone the repository\n",
        "!git clone https://github.com/smtiitm/Fastspeech2_HS.git\n",
        "%cd Fastspeech2_HS\n",
        "\n",
        "# Fetch all LFS files\n",
        "!git lfs fetch --all\n",
        "!git lfs pull\n",
        "\n",
        "# Install Miniconda\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "# Create the conda environment\n",
        "!conda env create -f environment.yml\n",
        "\n",
        "# Activate the environment\n",
        "!conda activate tts-hs-hifigan\n",
        "\n",
        "# Install PyTorch and dependencies\n",
        "!conda install pytorch cudatoolkit\n",
        "!pip install torchaudio\n",
        "\n",
        "# Clone and setup Vocoder (HIFIGAN)\n",
        "# (Refer to the repository instructions for setting up Vocoder)\n",
        "\n",
        "# Run inference to synthesize speech\n",
        "!python inference.py --sample_text \"Your input text here\" --language hindi --gender male --alpha 1 --output_file output.wav\n"
      ],
      "metadata": {
        "id": "nQsGurMPxAU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Fastspeech2_HS/inference.py --sample_text \"अपना इनपुट टेक्स्ट यहां दर्ज करें\" --language hindi --gender male --alpha 1 --output_file output2.wav\n",
        "#replace the path with your hifigan path to import Generator from models.py in inference.py"
      ],
      "metadata": {
        "id": "rBT-llC_lBU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Translation Model OpenAI"
      ],
      "metadata": {
        "id": "EzdJQnExfb88"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1ZEaXnE6fK0P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}